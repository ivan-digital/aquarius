# vLLM Inference with Docker, OpenTelemetry, Prometheus & Grafana

This repository demonstrates how to spin up a scalable vLLM-based inference service instrumented with OpenTelemetry metrics, collected by Prometheus, and visualized in Grafanaâ€”fronted by an Nginx reverse-proxy.

---

## Features

- **High-performance** vLLM inference container, GPU-accelerated  
- **OpenTelemetry** instrumentation for real-time metrics export  
- **Prometheus** scraping the `/metrics` endpoint  
- **Grafana** provisioning of dashboards & data sources (out-of-the-box)  
- **Nginx** as a reverse proxy with dynamic DNS resolution  

---

## Architecture

```text
+-----------+        +-------------+        +-------------+         +-----------+
|  Client   |  HTTP  |    Nginx    |  HTTP  |   vLLM API   |  ğŸ¡’ | GPU / ML  |
|  (curl,   | â”€â”€â”€â”€â–¶  |  (80/TCP)   | â”€â”€â”€â”€â–¶  | (8000/TCP)   |        |  Worker   |
|   Postman)|        +-------------+        /  + metrics \          +-----------+
|           |                                 â”‚ (9464/TCP)         
+-----------+                                 â–¼                   
                                       +-------------+            
                                       | Prometheus  |            
                                       |   (9090)    |            
                                       +-------------+            
                                             â”‚                  
                                             â–¼                  
                                       +-------------+            
                                       |   Grafana   |            
                                       |   (3000)    |            
                                       +-------------+            
```

---
## Inference folder Layout

```doctest
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ nginx/
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ datasources/datasources.yml
â”‚       â””â”€â”€ dashboards/dashboards.yml
â”‚       â””â”€â”€ dashboards/vllm.json
â””â”€â”€ vllm/
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ scripts/
        â””â”€â”€ run.sh
```

- docker-compose.yml â€“ declarative multiâ€container setup
- nginx/nginx.conf â€“ reverse proxy + /metrics proxying
- prometheus/prometheus.yml â€“ scrape vLLMâ€™s OpenTelemetry exporter
- grafana/provisioning/ â€“ pre-configured data source & dashboard
- vllm/ â€“ custom Dockerfile building vLLM + OpenTelemetry support

---
## Launch all services
```bash
docker-compose up --build -d
```
